{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "427951c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52616062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='D:/Course/Deep Learning/data'\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcf2f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split(data_Path,categories):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    img_size=100\n",
    "   \n",
    "\n",
    "    for category in categories:\n",
    "        folder_path=os.path.join(data_path,category)\n",
    "        img_names=os.listdir(folder_path)\n",
    "\n",
    "        for img_name in img_names:\n",
    "            img_path=os.path.join(folder_path,img_name)\n",
    "            img=cv2.imread(img_path)\n",
    "            \n",
    "            \n",
    "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)       \n",
    "            resized=cv2.resize(gray,(img_size,img_size))\n",
    "               \n",
    "            data.append(resized)\n",
    "            labels.append(label_dict[category])\n",
    "               \n",
    "     \n",
    "    \n",
    "    data=np.array(data)/255.0\n",
    "    data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return (data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7338858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels=load_split('D:/Course/Deep Learning/data',categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d179f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "new_labels=np_utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fec81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=200, kernel_size=(3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    " \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4361f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 98, 98, 200)       2000      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 49, 49, 200)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 47, 47, 100)       180100    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 23, 23, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 52900)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                3385664   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,567,894\n",
      "Trainable params: 3,567,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "227d1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "257cdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX,testX,trainY,testY=train_test_split(data,new_labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e55c75ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "166/166 [==============================] - 114s 682ms/step - loss: 0.6505 - accuracy: 0.6266\n",
      "Epoch 2/5\n",
      "166/166 [==============================] - 111s 671ms/step - loss: 0.5179 - accuracy: 0.7430\n",
      "Epoch 3/5\n",
      "166/166 [==============================] - 114s 685ms/step - loss: 0.3623 - accuracy: 0.8368\n",
      "Epoch 4/5\n",
      "166/166 [==============================] - 110s 665ms/step - loss: 0.2573 - accuracy: 0.8922\n",
      "Epoch 5/5\n",
      "166/166 [==============================] - 111s 667ms/step - loss: 0.1890 - accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14aa2046730>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(trainX, trainY, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d1b1774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 12s 162ms/step - loss: 0.3520 - accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3520066440105438, 0.865401566028595]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(testX,testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d92c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_clsfr=cv2.CascadeClassifier(\"D:/Course/Deep Learning/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "source=cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict={0:'NO MASK',1:'MASK'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d2365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df447a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "while(True):\n",
    "\n",
    "    ret,img=source.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_clsfr.detectMultiScale(img,1.3,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=cnn.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('img',img)\n",
    "    key=cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "source.release()        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725e1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
